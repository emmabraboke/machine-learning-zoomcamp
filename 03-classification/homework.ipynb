{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff1d934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a92f3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5502b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1462, 9)\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1462 entries, 0 to 1461\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   lead_source               1334 non-null   object \n",
      " 1   industry                  1328 non-null   object \n",
      " 2   number_of_courses_viewed  1462 non-null   int64  \n",
      " 3   annual_income             1281 non-null   float64\n",
      " 4   employment_status         1362 non-null   object \n",
      " 5   location                  1399 non-null   object \n",
      " 6   interaction_count         1462 non-null   int64  \n",
      " 7   lead_score                1462 non-null   float64\n",
      " 8   converted                 1462 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 102.9+ KB\n",
      "\n",
      "Missing values per column:\n",
      "lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data preparation - check for missing values\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nDataset info:\")\n",
    "df.info()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "45874003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['lead_source', 'industry', 'employment_status', 'location']\n",
      "Numerical columns: ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score', 'converted']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print(\"Numerical columns:\", numerical_cols)\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna('NA')\n",
    "\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6028e",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "What is the most frequent observation (mode) for the column industry?\n",
    "\n",
    "- NA\n",
    "- technology\n",
    "- healthcare\n",
    "- retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "23447b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent observation (mode) for 'industry' column: retail\n",
      "\n",
      "Value counts for 'industry':\n",
      "industry\n",
      "retail           203\n",
      "finance          200\n",
      "other            198\n",
      "healthcare       187\n",
      "education        187\n",
      "technology       179\n",
      "manufacturing    174\n",
      "NA               134\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "industry_mode = df['industry'].mode()[0]\n",
    "print(f\"Most frequent observation (mode) for 'industry' column: {industry_mode}\")\n",
    "print(f\"\\nValue counts for 'industry':\")\n",
    "print(df['industry'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a91b27",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "interaction_count and lead_score\n",
    "number_of_courses_viewed and lead_score\n",
    "number_of_courses_viewed and interaction_count\n",
    "annual_income and interaction_count\n",
    "Only consider the pairs above when answering this question.\n",
    "\n",
    "Split the data\n",
    "Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "Make sure that the target value converted is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "13c348ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
      "\n",
      "Correlation Matrix:\n",
      "                          number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                  1.000000       0.009770   \n",
      "annual_income                             0.009770       1.000000   \n",
      "interaction_count                        -0.023565       0.027036   \n",
      "lead_score                               -0.004879       0.015610   \n",
      "\n",
      "                          interaction_count  lead_score  \n",
      "number_of_courses_viewed          -0.023565   -0.004879  \n",
      "annual_income                      0.027036    0.015610  \n",
      "interaction_count                  1.000000    0.009888  \n",
      "lead_score                         0.009888    1.000000  \n",
      "\n",
      "Correlations for specified pairs:\n",
      "interaction_count and lead_score: 0.0099\n",
      "number_of_courses_viewed and lead_score: -0.0049\n",
      "number_of_courses_viewed and interaction_count: -0.0236\n",
      "annual_income and interaction_count: 0.0270\n"
     ]
    }
   ],
   "source": [
    "numerical_features = [col for col in numerical_cols if col != 'converted']\n",
    "print(\"Numerical features:\", numerical_features)\n",
    "\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "pairs = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'), \n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count')\n",
    "]\n",
    "\n",
    "print(\"\\nCorrelations for specified pairs:\")\n",
    "for pair in pairs:\n",
    "    if pair[0] in correlation_matrix.columns and pair[1] in correlation_matrix.columns:\n",
    "        corr_value = correlation_matrix.loc[pair[0], pair[1]]\n",
    "        print(f\"{pair[0]} and {pair[1]}: {corr_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3faf53a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1462, 8)\n",
      "Target shape: (1462,)\n",
      "Target distribution: converted\n",
      "1    905\n",
      "0    557\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train set: 877 samples (60.0%)\n",
      "Validation set: 292 samples (20.0%)\n",
      "Test set: 293 samples (20.0%)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('converted', axis=1)\n",
    "y = df['converted']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"Target distribution:\", y.value_counts())\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd335f",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Calculate the mutual information score between converted and other categorical variables in the dataset. Use the training set only.\n",
    "Round the scores to 2 decimals using round(score, 2).\n",
    "Which of these variables has the biggest mutual information score?\n",
    "\n",
    "industry\n",
    "location\n",
    "lead_source\n",
    "employment_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7bcd13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information scores:\n",
      "lead_source: 0.03\n",
      "industry: 0.0\n",
      "employment_status: 0.0\n",
      "location: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "categorical_features = [col for col in categorical_cols if col != 'converted']\n",
    "\n",
    "X_train_encoded = pd.DataFrame()\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X_train_encoded[col] = le.fit_transform(X_train[col].astype(str))\n",
    "\n",
    "mi_scores = mutual_info_classif(X_train_encoded, y_train, random_state=42)\n",
    "\n",
    "question_features = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "print(\"Mutual Information scores:\")\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    if feature in question_features:\n",
    "        score = round(mi_scores[i], 2)\n",
    "        print(f\"{feature}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7adef0",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Now let's train a logistic regression.\n",
    "Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "Fit the model on the training dataset.\n",
    "To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "What accuracy did you get?\n",
    "\n",
    "0.64\n",
    "0.74\n",
    "0.84\n",
    "0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4ab7cba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['lead_source', 'industry', 'employment_status', 'location']\n",
      "Numerical features: ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
      "Validation accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "categorical_features = [col for col in categorical_cols if col != 'converted']\n",
    "numerical_features = [col for col in numerical_cols if col != 'converted']\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Numerical features:\", numerical_features)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "accuracy_rounded = round(accuracy, 2)\n",
    "\n",
    "print(f\"Validation accuracy: {accuracy_rounded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10aadae",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Let's find the least useful feature using the feature elimination technique.\n",
    "Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "- 'industry'\n",
    "- 'employment_status'\n",
    "- 'lead_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "274ab4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: 0.684931506849315\n",
      "\n",
      "Smallest difference: industry\n"
     ]
    }
   ],
   "source": [
    "original_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Original accuracy: {original_accuracy}\")\n",
    "\n",
    "test_features = ['industry', 'employment_status', 'lead_score']\n",
    "feature_differences = {}\n",
    "\n",
    "for feature in test_features:\n",
    "    # Remove feature from appropriate list\n",
    "    if feature in categorical_features:\n",
    "        cat_reduced = [col for col in categorical_features if col != feature]\n",
    "        preprocessor_reduced = ColumnTransformer([\n",
    "            ('num', 'passthrough', numerical_features),\n",
    "            ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_reduced)\n",
    "        ])\n",
    "    else:\n",
    "        num_reduced = [col for col in numerical_features if col != feature]\n",
    "        preprocessor_reduced = ColumnTransformer([\n",
    "            ('num', 'passthrough', num_reduced),\n",
    "            ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Train model without this feature\n",
    "    model_reduced = Pipeline([\n",
    "        ('preprocessor', preprocessor_reduced),\n",
    "        ('classifier', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    model_reduced.fit(X_train, y_train)\n",
    "    accuracy_reduced = accuracy_score(y_val, model_reduced.predict(X_val))\n",
    "    difference = original_accuracy - accuracy_reduced\n",
    "    feature_differences[feature] = difference\n",
    "    \n",
    "min_feature = min(feature_differences, key=feature_differences.get)\n",
    "print(f\"\\nSmallest difference: {min_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cca29b",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Now let's train a regularized logistic regression.\n",
    "Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "Train models using all the features as in Q4.\n",
    "Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "Which of these C leads to the best accuracy on the validation set?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "- 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "af03644a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: Accuracy = 0.685\n",
      "C = 0.1: Accuracy = 0.685\n",
      "C = 1: Accuracy = 0.685\n",
      "C = 10: Accuracy = 0.685\n",
      "C = 100: Accuracy = 0.685\n",
      "\n",
      "Best C value: 0.01 with accuracy: 0.685\n"
     ]
    }
   ],
   "source": [
    "# Question 6: Regularized logistic regression with different C values\n",
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "results = {}\n",
    "\n",
    "for c in c_values:\n",
    "    model_c= Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42))\n",
    "    ])\n",
    "    \n",
    "\n",
    "    model_c.fit(X_train, y_train)\n",
    "    y_val_pred_c = model_c.predict(X_val)\n",
    "    accuracy_c = accuracy_score(y_val, y_val_pred_c)\n",
    "    results[c] = round(accuracy_c, 3)\n",
    "    \n",
    "    print(f\"C = {c}: Accuracy = {results[c]}\")\n",
    "\n",
    "best_c = max(results, key=results.get)\n",
    "print(f\"\\nBest C value: {best_c} with accuracy: {results[best_c]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
